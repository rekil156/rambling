{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://rekil156.github.io/rambling/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "!pip install fastai2 -q . from fastai2.vision.all import * . This mainly contains the different ways we can use the POWERFUL DATABLOCKS api to bring in data. Download the dataset and give it try. There are a few ways to do this so the ways i have done it may not be the only way (and not the best way ). In the more you can see where the whole solution ie datablocks + learner code is available. First resourse to checkout are the tutorials . Curretly we&#39;ll focus on how how we can use source(paths or dfs) and set out get_x, get_y, get_items. Splitters and Item/Batch Tfms - will update later . Classification . Single label classification . (ImageBlock(cls=PILImageBW), CategoryBlock . path = untar_data(URLs.MNIST_TINY) !ls {path} . labels.csv models test train valid . df = pd.read_csv(path/&#39;labels.csv&#39;) df.head(2) . name label . 0 train/3/7463.png | 3 | . 1 train/3/9829.png | 3 | . mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), get_x=ColReader(0, pref=f&#39;{path}/&#39;), get_y=ColReader(1), splitter =RandomSplitter(), item_tfms = [CropPad(34),RandomCrop(28)], batch_tfms = [Normalize()], ) dl = mnist.dataloaders(df) dl.show_batch(max_n=2) . Experiments, high level understanding . 1) Let&#39;s change ImageBlock(cls=PILImageBW) to ImageBlock() . mnist = DataBlock(blocks=(ImageBlock(), CategoryBlock), get_x=ColReader(0, pref=f&#39;{path}/&#39;), get_y=ColReader(1), splitter =RandomSplitter(), item_tfms = [CropPad(34),RandomCrop(28)], batch_tfms = [Normalize()], ) dls = mnist.dataloaders(df) dls.show_batch(max_n=2) . Wow that seems to work too.We see &#39;3&#39; and &#39;7&#39; Hang on it looks different though, the colors are inverted. TODO:This shouldn&#39;t effect the training of the model(haven&#39;t tried it out). Let&#39;s look at ImageBlock. (??ImageBlock) . def ImageBlock(cls=PILImage): &quot;A `TransformBlock` for images of `cls`&quot; return TransformBlock(type_tfms=cls.create, batch_tfms=IntToFloatTensor) . The default cls is PILImage which is an RGB image. For single channel images you want to pass cls=PILImageBW. Later we&#39;ll see how we pass in a 4-channel image. Other thing to notice in the code is batch_tfms=IntToFloatTensor, we&#39;ll discuss that shortly. . 2) Change CategoryBlock to CategoryBlock() . mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock()), get_x=ColReader(0, pref=f&#39;{path}/&#39;), get_y=ColReader(1), splitter =RandomSplitter(), item_tfms = [CropPad(34),RandomCrop(28)], batch_tfms = [Normalize()], ) dls = mnist.dataloaders(df) dls.show_batch(max_n=2) . This looks good. The answer is in ??DataBlock. blocks = L(b() if callable(b) else b for b in blocks) . 3)What are the batch tranforms that are being applied? We asked for Normalize. Let&#39;s check . dls.train.after_batch . Pipeline: IntToFloatTensor -&gt; Normalize . Rememeber what we saw in ??ImageBlock - batch_tfms=IntToFloatTensor. That is being applied automatically for us. So now replace batch_tfms = [Normalize()] with batch_tfms = [IntToFloatTensor(),Normalize()]. It should all be good. But wait, didn&#39;t we apply IntToFloatTensor twice ? Don&#39;t worry duplicates are removed look at _merge_tfms in block.py. So the different TransformBlocks may have different default type_tfms, item_tfms, batch_tfms. . Similarly ToTensor() is applied automatically for item_tfms. . self.type_tfms = L(type_tfms) self.item_tfms = ToTensor + L(item_tfms) self.batch_tfms = L(batch_tfms) . Now lets try the same thing with get_items . def _mnist_items(x): return (f&#39;{path}/&#39;+x.name,x.label) mnist = DataBlock.from_columns(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), get_items = _mnist_items, splitter =RandomSplitter(), ) dls = mnist.dataloaders(df) dls.show_batch(max_n=2) . Note: i always forget the from_columns in DataBlock.from_columns . What is _mnist_items, how to build it? . We need a x and y to train. More specifically we need a Tuple ie (x,y). We have to get this from our df. Our x are image names in column &#39;name&#39;.(we need the full path to grab the image from) Our y are the labels in column &#39;labels&#39;. . See what _mnist_items(df) gives you. . df.name, df.label . df.values . array([[&#39;train/3/7463.png&#39;, 3], [&#39;train/3/9829.png&#39;, 3], [&#39;train/3/7881.png&#39;, 3], ..., [&#39;valid/7/0.png&#39;, 7], [&#39;valid/7/8282.png&#39;, 7], [&#39;valid/7/7149.png&#39;, 7]], dtype=object) . Explanation ..... TODO . Predict a list of numbers. . (ImageBlock, RegressionBlock(c_out=4) (image_id, [healthy multiple_diseases rust scab]). Look at show_batch so see the particular case . Here we deal with a single leaf image and we have to predict wether the leaf is healthy, has multiple diseases, has rust, has scab. So one input image and 4 columns to predict. In the evaluation we have For each image_id in the test set, you must predict a probability for each target variable. so we&#39;ll set it up as a regression problem. The data is available here. TODO: upload tiny data . path= &#39;&#39;&#39;drive/My Drive/kaggle/plant/&#39;&#39;&#39; . train = pd.read_csv(path+&#39;train.csv&#39;) train.head(2) . image_id healthy multiple_diseases rust scab . 0 Train_0 | 0 | 0 | 0 | 1 | . 1 Train_1 | 0 | 1 | 0 | 0 | . We need to create a tuple is (x,y) for our model to train. So we&#39;ll create like this (image_id, [healthy multiple_diseases rust scab])Let&#39;s create a new column combined which is a list of the dependent variables. (This is not the only way to solve this problem) . train[&#39;combined&#39;] = train[[&#39;healthy&#39;,&#39;multiple_diseases&#39;,&#39;rust&#39;,&#39;scab&#39;]].values.tolist() train.head(2) . image_id healthy multiple_diseases rust scab combined . 0 Train_0 | 0 | 0 | 0 | 1 | [0, 0, 0, 1] | . 1 Train_1 | 0 | 1 | 0 | 0 | [0, 1, 0, 0] | . &#39;show_batch&#39; fixes to show a list (not yet perect) . For show_batch to work we need to add the ability for a list to have show_title . class TitledList(list, ShowTitle): _show_args = {&#39;label&#39;: &#39;text&#39;} def show(self, ctx=None, **kwargs): &quot;Show self&quot; return show_title(self, ctx=ctx, **merge(self._show_args, kwargs)) . class ToListTensor(Transform): &quot;Transform to int tensor&quot; # order = 10 #Need to run after PIL transforms on the GPU _show_args = {&#39;label&#39;: &#39;text&#39;} def __init__(self, split_idx=None,): super().__init__(split_idx=split_idx) def encodes(self, o): return o # def decodes(self, o): return TitledNumberShort(o) def decodes(self, o): return TitledList(o) . Independent variable is the image we&#39;ll use a ImageBlock. Dependent varaible we&#39;ll use a RegressionBlock, here we need to set c_out. And we add ToListTensor to the get_y . plant = DataBlock(blocks =(ImageBlock, RegressionBlock(c_out=4)), get_x = ColReader(&#39;image_id&#39;, pref=f&#39;drive/My Drive/kaggle/plant/images/&#39;,suff=&#39;.jpg&#39;), get_y = [ColReader(&#39;combined&#39;),ToListTensor], splitter =RandomSplitter(), item_tfms=[Resize(150)], batch_tfms = [*aug_transforms()], ) dls = plant.dataloaders(train) dls.show_batch(nrows=1,ncols=2,figsize=(10,10)) . I have a full pipeline here here . 4 channel input image . Kaggle Competition This was worked on by a group of us look here for the write-up - ???? @akashpalrecha, @aman, @init_27 (am i missing anyone else please let me know) . Each image in the dataset is a single channel black and white image. We need to combine 4 of them to make a 4-channel image. Given this 4-channel image we want to predict multiple categories. . We have: fname_red.png fname_green.png fname_blue.png fname_yellow.png This four need to be stacked to form one single 4-channeled image. This gives a clear understanding of when to use get_items, get_x, get_y. . data_path = Path(&#39;/storage/data/atlas/train&#39;) files = get_image_files(data_path) . def custom_get(path):#files are in sets of four files = get_image_files(path) files = sorted(files) return files[slice(0, len(files), 4)] . def comb_4img(fname):#combine four 1-channel image to get one 4-channel image fname = str(fname) suffix = &#39;.png&#39; if fname.endswith(&#39;.png&#39;) or fname.endswith(&#39;.tif&#39;): suffix = fname[-4:] fname = fname.split(&#39;_&#39;)[0] colors = [&#39;red&#39;,&#39;green&#39;,&#39;blue&#39;,&#39;yellow&#39;] img = [Image.open(fname+&#39;_&#39;+color+suffix) for color in colors] x = np.stack(img, axis=-1) return PILImage.create(x) . df = pd.read_csv(&quot;../data/atlas/train.csv&quot;) df.set_index(&quot;Id&quot;, inplace=True) def get_y(path, df=df): path = Path(path) path = path.stem path = path[:-5] return df.loc[path].values[0].split(&quot; &quot;) . atlas = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), get_items=custom_get, get_x=comb_4img, get_y=get_y ) dls = atlas.dataloaders(data_path,bs=2) dls.show_batch() . getters example . SO we need a get_items to get the files, get_x, get_y for (x,y). Some times no get_x, why ? what happens if you add get_x to that mnist_tiny example . 1-ch vs 3-ch . fn . (#1428) [Path(&#39;/root/.fastai/data/mnist_tiny/train/3/9153.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/9324.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/8830.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/9621.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/7862.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/8075.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/8816.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/8227.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/715.png&#39;),Path(&#39;/root/.fastai/data/mnist_tiny/train/3/7067.png&#39;)...] . net = resnet18(pretrained=True,) . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth . . net.conv1.weight.shape . torch.Size([64, 3, 7, 7]) .",
            "url": "https://rekil156.github.io/rambling/2020/01/28/DataBlock_Playground.html",
            "relUrl": "/2020/01/28/DataBlock_Playground.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://rekil156.github.io/rambling/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rekil156.github.io/rambling/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}